import sys
import os
import asyncio
import logging
from DrissionPage import Chromium, ChromiumOptions


# æ—¥å¿—é…ç½®
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
file_handler = logging.FileHandler('./app.log')
file_handler.setLevel(logging.INFO)
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='[%Y-%m-%d %H:%M:%S]')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)
logger.addHandler(file_handler)
logger.addHandler(console_handler)


# æ¯ä¸ª URL é…ç½®ï¼šæ£€æŸ¥åœ°å€ã€æ‰“å¼€åœ°å€ã€æŸ¥æ‰¾å…ƒç´ ã€è½®è¯¢é—´éš”ï¼ˆå•ä½ï¼šç§’ï¼‰
URL_CONFIGS = [
    {
        'check_url': 'https://bashinfo.zhouhuimin.qzz.io/',
        'open_url': 'https://idx.google.com/',
        'keys': 'xray-keep',
        'interval': 600
    },
    {
        'check_url': 'http://node23.lunes.host:3112/',
        'open_url': 'https://ctrl.lunes.host/',
        'keys': 'my-server',
        'interval': 600
    }
]

MONITOR_INTERVAL = 10  # æµè§ˆå™¨ä»»åŠ¡ä¸­çš„ curl æ£€æµ‹é—´éš”

async def check_url_loop(config):
    check_url = config['check_url']
    open_url = config['open_url']
    keys = config['keys']
    interval = config['interval']

    while True:
        proc = await asyncio.create_subprocess_exec(
            'curl', '-i', check_url,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, _ = await proc.communicate()
        output = stdout.decode()

        first_line = output.split('\n', 1)[0].rstrip('\r\n') if output else "No output"
        logger.info(f"{check_url} è¿”å› {first_line}")

        if "200" not in first_line:
            logger.warning(f"âœ… åˆ›å»ºæµè§ˆå™¨æ‰“å¼€æŒ‡å®šé¡µé¢ [{open_url}]")
            await handle_browser_task(check_url, open_url, keys)

        await asyncio.sleep(interval)


async def handle_browser_task(check_url, open_url, keys):
    co = ChromiumOptions().headless()
    co.set_paths(browser_path='/var/lib/snapd/snap/bin/chromium')
    co.set_user_data_path('./Default')
    co.set_proxy('http://192.168.200.14:10888')
    co.set_argument('--no-sandbox')
    co.set_argument('--disable-dev-shm-usage')
    co.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36')

    browser = Chromium(co)
    tab = browser.new_tab()

    tab.get(open_url)
    #æŸ¥æ‰¾æŒ‡å®šå…³é”®å­— æ²¡æœ‰æ‰¾åˆ°è¯´æ˜ç™»å½•å¤±è´¥
    ele = tab.ele(f'xpath://*[contains(text(), "{keys}")]', timeout=30)

    if keys in tab.html:
        logger.info(f'âœ… åœ¨ {open_url} æ‰¾åˆ°[{keys}]')
        ele.click()
        tab.wait.doc_loaded()
        logger.info(f'ğŸš€ æ­£åœ¨æ‰“å¼€é¡µé¢ [{open_url}][{keys}]')

        stop_event = asyncio.Event()

        async def monitor_http_status():
            while not stop_event.is_set():
                proc = await asyncio.create_subprocess_exec(
                    'curl', '-i', check_url,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                stdout, _ = await proc.communicate()
                output = stdout.decode()

                first_line = output.split('\n', 1)[0].rstrip('\r\n') if output else "No output"
                logger.info(f"[monitor] {check_url} {first_line}")

                if "200" in first_line:
                    logger.info(f"ğŸŸ¢ curl æ£€æµ‹åˆ° {check_url} HTTP/2 200ï¼Œ10 ç§’åå…³é—­æµè§ˆå™¨é‡Šæ”¾èµ„æº")
                    stop_event.set()
                    await asyncio.sleep(10)
                    browser.quit()
                    logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
                    os.system("pkill -f chromium 2>/dev/null")
                    logger.info("âœ… æµè§ˆå™¨å·²å…³é—­")
                    return

                await asyncio.sleep(MONITOR_INTERVAL)

        monitor_task = asyncio.create_task(monitor_http_status())

        try:
            await asyncio.wait_for(stop_event.wait(), timeout=220)
        except asyncio.TimeoutError:
            logger.info(f'ğŸ”„ å·²è¿‡3åˆ†é’Ÿï¼Œåˆ·æ–°é¡µé¢{open_url}...')
            tab.refresh()
            try:
                await asyncio.wait_for(stop_event.wait(), timeout=200)
            except asyncio.TimeoutError:
                # å–æ¶ˆç›‘æ§ä»»åŠ¡
                logger.info("ğŸ›‘ æ­£åœ¨å–æ¶ˆ monitor_task ...")
                monitor_task.cancel()
                try:
                    await monitor_task
                except asyncio.CancelledError:
                    logger.info("ğŸ›‘ monitor_task å·²å–æ¶ˆ")
                except Exception as e:
                    logger.warning(f"âš ï¸ monitor_task å–æ¶ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

                logger.info("â³ é¡µé¢å·²æ‰“å¼€é¢å¤– 200 ç§’ï¼Œå…³é—­æµè§ˆå™¨")
                browser.quit()
                logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
                os.system("pkill -f chromium")
                logger.info("âœ… æµè§ˆå™¨å·²å…³é—­ï¼ˆè¶…æ—¶ï¼‰")

    else:
        logger.warning(f'âŒ æ²¡æœ‰æ‰¾åˆ°[{keys}] éœ€è¦ç™»å½•')
        browser.quit()
        logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
        os.system("pkill -f chromium")
        logger.info("âœ… æµè§ˆå™¨å·²å…³é—­ï¼ˆæœªæ‰¾åˆ°å…³é”®å­—ï¼‰")



async def main():
    tasks = [check_url_loop(config) for config in URL_CONFIGS]
    await asyncio.gather(*tasks)

if __name__ == '__main__':
    asyncio.run(main())

