import sys
import os
import asyncio
import logging
from DrissionPage import Chromium, ChromiumOptions

# æ—¥å¿—é…ç½®
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
file_handler = logging.FileHandler('./app.log')
file_handler.setLevel(logging.INFO)
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='[%Y-%m-%d %H:%M:%S]')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# é…ç½®å‚æ•°
URL_INDEX = 'https://idx.google.com/'

# æ¯ä¸ª URL é…ç½®ï¼šæ£€æŸ¥åœ°å€ã€æ‰“å¼€åœ°å€ã€è½®è¯¢é—´éš”ï¼ˆå•ä½ï¼šç§’ï¼‰
URL_CONFIGS = [
    {
        'check_url': 'idxå¤–éƒ¨åœ°å€1',
        'open_url': 'https://idx.google.com/xray-keep-55221223',
        'interval': 600  # æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    },
    {
        'check_url': 'idxå¤–éƒ¨åœ°å€2',
        'open_url': 'https://idx.google.com/vpn-2-59362180',
        'interval': 120  # æ¯ 1 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    },
    # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šé…ç½®é¡¹
]

MONITOR_INTERVAL = 10  # æµè§ˆå™¨ä»»åŠ¡ä¸­çš„ curl æ£€æµ‹é—´éš”

async def check_url_loop(config):
    check_url = config['check_url']
    open_url = config['open_url']
    interval = config['interval']

    while True:
        proc = await asyncio.create_subprocess_exec(
            'curl', '-I', check_url,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, _ = await proc.communicate()
        output = stdout.decode()

        first_line = output.split('\n', 1)[0].rstrip('\r\n') if output else "No output"
        logger.info(f"{check_url} è¿”å› {first_line}")

        if "HTTP/2 200" not in output:
            logger.info(f"âœ… åˆ›å»ºæµè§ˆå™¨æ‰“å¼€æŒ‡å®šé¡µé¢ [{open_url}]")
            await handle_browser_task(check_url, open_url)

        await asyncio.sleep(interval)


async def handle_browser_task(check_url, open_url):
    co = ChromiumOptions().headless()
    co.set_paths(browser_path='/var/lib/snapd/snap/bin/chromium')
    co.set_user_data_path('./Default')
    co.set_proxy('http://192.168.200.14:10888')
    co.set_argument('--no-sandbox')
    co.set_argument('--disable-dev-shm-usage')
    co.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36')

    browser = Chromium(co)
    tab = browser.latest_tab

    #æ‰“å¼€ä¸»é¡µ
    tab.get(URL_INDEX)
    
    #æŸ¥æ‰¾ç™»å½•åçš„é¡µé¢å…³é”®å­— æ‰¾åˆ°è¯´æ˜ç™»å½•æˆåŠŸ ç™»å½•æˆåŠŸåæ‰“å¼€é¡¹ç›®
    ele = tab.ele('xpath://*[contains(text(), "xray-keep")]', timeout=30)

    if 'xray-keep' in tab.html:
        logger.info('âœ… æ‰¾åˆ°[xray-keep]')
        logger.info('â³ ç­‰å¾… 5 ç§’åæ‰“å¼€é¡µé¢...')
        await asyncio.sleep(5)
        tab.get(open_url)
        logger.info(f'ğŸš€ æ­£åœ¨æ‰“å¼€é¡µé¢ {open_url}...')

        stop_event = asyncio.Event()

        async def monitor_http_status():
            while not stop_event.is_set():
                proc = await asyncio.create_subprocess_exec(
                    'curl', '-I', check_url,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                stdout, _ = await proc.communicate()
                output = stdout.decode()

                first_line = output.split('\n', 1)[0].rstrip('\r\n') if output else "No output"
                logger.info(f"[monitor] {check_url} {first_line}")

                if "HTTP/2 200" in output:
                    logger.info("ğŸŸ¢ curl æ£€æµ‹åˆ° HTTP/2 200ï¼Œ10 ç§’åå…³é—­æµè§ˆå™¨é‡Šæ”¾èµ„æº")
                    stop_event.set()
                    await asyncio.sleep(10)
                    browser.quit()
                    logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
                    os.system("pkill -f chromium 2>/dev/null")
                    logger.info("âœ… æµè§ˆå™¨å·²å…³é—­")
                    return

                await asyncio.sleep(MONITOR_INTERVAL)

        monitor_task = asyncio.create_task(monitor_http_status())

        try:
            await asyncio.wait_for(stop_event.wait(), timeout=250)
        except asyncio.TimeoutError:
            logger.info('ğŸ”„ å·²è¿‡4åˆ†é’Ÿï¼Œåˆ·æ–°é¡µé¢...')
            tab.refresh()
            try:
                await asyncio.wait_for(stop_event.wait(), timeout=120)
            except asyncio.TimeoutError:
                logger.info("â³ é¡µé¢å·²æ‰“å¼€é¢å¤– 100 ç§’ï¼Œå…³é—­æµè§ˆå™¨")
                browser.quit()
                logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
                os.system("pkill -f chromium")
                logger.info("âœ… æµè§ˆå™¨å·²å…³é—­ï¼ˆè¶…æ—¶ï¼‰")

    else:
        logger.warning('âŒ æ²¡æœ‰æ‰¾åˆ°[xray-keep]')
        browser.quit()
        logger.info("ğŸ§¹ å°è¯•æ¸…ç†æ®‹ç•™çš„ chromium è¿›ç¨‹...")
        os.system("pkill -f chromium")
        logger.info("âœ… æµè§ˆå™¨å·²å…³é—­ï¼ˆæœªæ‰¾åˆ°å…³é”®å­—ï¼‰")



async def main():
    tasks = [check_url_loop(config) for config in URL_CONFIGS]
    await asyncio.gather(*tasks)

if __name__ == '__main__':
    asyncio.run(main())
